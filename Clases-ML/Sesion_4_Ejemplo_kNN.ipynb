{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bd4hBDuoWdxp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import make_moons, make_classification\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, Normalizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "np.random.seed(42)\n",
        "os.makedirs(\"figs\", exist_ok=True)\n",
        "\n",
        "# Helpers de ploteo para fronteras 2D\n",
        "def plot_decision_boundary(clf, X, y, ax, title=\"\", step=0.02, proba_class=1):\n",
        "    # malla\n",
        "    x_min, x_max = X[:,0].min()-0.8, X[:,0].max()+0.8\n",
        "    y_min, y_max = X[:,1].min()-0.8, X[:,1].max()+0.8\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, step),\n",
        "                         np.arange(y_min, y_max, step))\n",
        "    # proba de clase 1 (si no tiene predict_proba, usar 0/1 de predict)\n",
        "    if hasattr(clf, \"predict_proba\"):\n",
        "        Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, proba_class]\n",
        "    else:\n",
        "        Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "    # fondo\n",
        "    cs = ax.contourf(xx, yy, Z, alpha=0.25, levels=25)\n",
        "    # fronteras al 0.5 si hay proba\n",
        "    if hasattr(clf, \"predict_proba\"):\n",
        "        ax.contour(xx, yy, Z, levels=[0.5], colors=\"k\", linewidths=1.2)\n",
        "    # puntos\n",
        "    ax.scatter(X[y==0,0], X[y==0,1], s=20, c=\"tab:blue\", edgecolors=\"k\", label=\"Clase 0\")\n",
        "    ax.scatter(X[y==1,0], X[y==1,1], s=20, c=\"tab:red\",  edgecolors=\"k\", label=\"Clase 1\")\n",
        "    ax.set_title(title)\n",
        "    ax.set_xlabel(\"$x_1$\"); ax.set_ylabel(\"$x_2$\")\n",
        "    ax.set_xlim(x_min, x_max); ax.set_ylim(y_min, y_max)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_knn, y_knn = make_moons(n_samples=1000, noise=0.25, random_state=42)\n",
        "Xtr_knn, Xte_knn, ytr_knn, yte_knn = train_test_split(\n",
        "    X_knn, y_knn, test_size=0.25, random_state=42, stratify=y_knn\n",
        ")\n",
        "\n",
        "Xtr_knn.shape, Xte_knn.shape, np.bincount(y_knn)"
      ],
      "metadata": {
        "id": "ECVZrF0mWwKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler_for_vi = StandardScaler()\n",
        "Xtr_scaled = scaler_for_vi.fit_transform(Xtr_knn)\n",
        "cov = np.cov(Xtr_scaled, rowvar=False)\n",
        "VI = np.linalg.inv(cov + 1e-6*np.eye(cov.shape[0]))  # regularización\n",
        "\n",
        "# Definimos configuraciones: (etiqueta, pipeline)\n",
        "def knn_pipeline(metric, metric_params=None, weights=\"uniform\", n_neighbors=7, cosine_norm=False, mahalanobis_VI=None):\n",
        "    steps = [(\"sc\", StandardScaler())]\n",
        "    # Para coseno conviene normalizar (ángulo):\n",
        "    if metric == \"cosine\" or cosine_norm:\n",
        "        steps.append((\"norm\", Normalizer(norm=\"l2\")))\n",
        "    if metric == \"mahalanobis\":\n",
        "        clf = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights,\n",
        "                                   metric=metric, metric_params={\"VI\": mahalanobis_VI})\n",
        "    else:\n",
        "        clf = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights,\n",
        "                                   metric=metric, metric_params=metric_params)\n",
        "    steps.append((\"knn\", clf))\n",
        "    return Pipeline(steps)\n",
        "\n",
        "configs = [\n",
        "    (\"L2 / uniform\",   knn_pipeline(\"minkowski\", {\"p\":2}, weights=\"uniform\")),\n",
        "    (\"L2 / distance\",  knn_pipeline(\"minkowski\", {\"p\":2}, weights=\"distance\")),\n",
        "    (\"L1 / uniform\",   knn_pipeline(\"minkowski\", {\"p\":1}, weights=\"uniform\")),\n",
        "    (\"L∞ / uniform\",   knn_pipeline(\"chebyshev\", None,    weights=\"uniform\")),\n",
        "    (\"coseno / uniform\", knn_pipeline(\"cosine\", None, weights=\"uniform\", cosine_norm=True)),\n",
        "    (\"Mahalanobis / uniform\", knn_pipeline(\"mahalanobis\", None, weights=\"uniform\", mahalanobis_VI=VI)),\n",
        "]\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "means, stds = [], []\n",
        "for name, pipe in configs:\n",
        "    scores = cross_val_score(pipe, Xtr_knn, ytr_knn, cv=skf, scoring=\"accuracy\", n_jobs=-1)\n",
        "    means.append(scores.mean()); stds.append(scores.std())\n",
        "    print(f\"{name:22s}  CV acc: {scores.mean():.3f} ± {scores.std():.3f}\")\n",
        "\n",
        "# Barplot de CV\n",
        "plt.figure(figsize=(8,4))\n",
        "x = np.arange(len(configs))\n",
        "plt.bar(x, means, yerr=stds, capsize=4)\n",
        "plt.xticks(x, [c[0] for c in configs], rotation=20)\n",
        "plt.ylabel(\"Accuracy (CV)\")\n",
        "plt.title(\"k-NN: comparación de métricas y pesos (CV 5-fold)\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"figs/knn_cv_metrics_bar.png\", dpi=200, bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "\n",
        "# Fronteras (4 paneles principales)\n",
        "fig, axes = plt.subplots(2, 3, figsize=(12,8))\n",
        "axes = axes.ravel()\n",
        "for ax, (name, pipe) in zip(axes, configs):\n",
        "    pipe.fit(Xtr_knn, ytr_knn)\n",
        "    plot_decision_boundary(pipe, Xtr_knn, ytr_knn, ax, title=name)\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"figs/knn_boundaries_grid.png\", dpi=200, bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "\n",
        "# Evaluación en test para el mejor según CV\n",
        "best_idx = int(np.argmax(means))\n",
        "best_name, best_pipe = configs[best_idx]\n",
        "best_pipe.fit(Xtr_knn, ytr_knn)\n",
        "acc_test = accuracy_score(yte_knn, best_pipe.predict(Xte_knn))\n",
        "print(f\"Mejor config por CV: {best_name} | Test acc: {acc_test:.3f}\")"
      ],
      "metadata": {
        "id": "zkTs5CTnWzwk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Perceptron"
      ],
      "metadata": {
        "id": "jL1Gm_XIYhDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_circles\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Círculos con ruido -> NO linealmente separable\n",
        "X_perc, y_perc01 = make_circles(n_samples=600, factor=0.45, noise=0.18, random_state=12)\n",
        "y_perc = np.where(y_perc01==1, 1, -1)  # etiquetas {-1, +1}\n",
        "\n",
        "# Estandarizar\n",
        "sc_p = StandardScaler().fit(X_perc)\n",
        "X_perc_s = sc_p.transform(X_perc)\n",
        "\n",
        "plt.figure(figsize=(4.8,4.2))\n",
        "plt.scatter(X_perc_s[y_perc==-1,0], X_perc_s[y_perc==-1,1], s=15, c=\"tab:blue\", edgecolors=\"k\", label=\"y=-1\")\n",
        "plt.scatter(X_perc_s[y_perc==+1,0], X_perc_s[y_perc==+1,1], s=15, c=\"tab:red\",  edgecolors=\"k\", label=\"y=+1\")\n",
        "plt.legend(); plt.title(\"Círculos concéntricos (no lineal)\")\n",
        "plt.xlabel(\"$x_1$ (std)\"); plt.ylabel(\"$x_2$ (std)\")\n",
        "plt.tight_layout(); plt.show()"
      ],
      "metadata": {
        "id": "eA6sVhuhYjnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perceptron_train(X, y, eta=1.0, max_epochs=50, shuffle=True):\n",
        "    n, d = X.shape\n",
        "    w = np.zeros(d); b = 0.0\n",
        "    history = []  # (w, b, errors)\n",
        "    rng = np.random.RandomState(0)\n",
        "    for epoch in range(max_epochs):\n",
        "        idx = np.arange(n)\n",
        "        if shuffle:\n",
        "            rng.shuffle(idx)\n",
        "        errors = 0\n",
        "        for i in idx:\n",
        "            margin = y[i]*(np.dot(w, X[i]) + b)\n",
        "            if margin <= 0:\n",
        "                w = w + eta*y[i]*X[i]\n",
        "                b = b + eta*y[i]\n",
        "                errors += 1\n",
        "        history.append((w.copy(), b, errors))\n",
        "        # En datos NO separables, lo normal es que errors > 0 siempre.\n",
        "    return w, b, history\n",
        "\n",
        "def plot_separator(ax, w, b, **kwargs):\n",
        "    x_min, x_max = ax.get_xlim()\n",
        "    x_vals = np.array([x_min, x_max])\n",
        "    if abs(w[1]) < 1e-9:\n",
        "        x0 = -b / (w[0] + 1e-9)\n",
        "        ax.plot([x0, x0], ax.get_ylim(), **kwargs)\n",
        "    else:\n",
        "        y_vals = -(w[0]/w[1])*x_vals - b/(w[1]+1e-12)\n",
        "        ax.plot(x_vals, y_vals, **kwargs)\n",
        "\n",
        "\n",
        "w_star, b_star, hist = perceptron_train(X_perc_s, y_perc, eta=1.0, max_epochs=200, shuffle=True)\n",
        "\n",
        "print(f\"Épocas totales: {len(hist)}\")\n",
        "print(f\"Errores en últimas 5 épocas: {[e for (_,_,e) in hist[-5:]]}\")\n",
        "\n",
        "# ----------------- PLOT FINAL -----------------\n",
        "fig, ax = plt.subplots(figsize=(5.5,4.5))\n",
        "ax.scatter(X_perc_s[y_perc==-1,0], X_perc_s[y_perc==-1,1], s=15, c=\"tab:blue\", edgecolors=\"k\", label=\"y=-1\")\n",
        "ax.scatter(X_perc_s[y_perc==+1,0], X_perc_s[y_perc==+1,1], s=15, c=\"tab:red\",  edgecolors=\"k\", label=\"y=+1\")\n",
        "ax.set_title(\"Perceptrón en dataset no lineal (no converge)\")\n",
        "ax.set_xlabel(\"$x_1$ (std)\"); ax.set_ylabel(\"$x_2$ (std)\")\n",
        "\n",
        "# límites y recta\n",
        "x_min, x_max = X_perc_s[:,0].min()-0.8, X_perc_s[:,0].max()+0.8\n",
        "y_min, y_max = X_perc_s[:,1].min()-0.8, X_perc_s[:,1].max()+0.8\n",
        "ax.set_xlim(x_min, x_max); ax.set_ylim(y_min, y_max)\n",
        "plot_separator(ax, w_star, b_star, color=\"k\", linewidth=2)\n",
        "\n",
        "# etiqueta sobre la recta\n",
        "xm = 0.5*(x_min+x_max)\n",
        "if abs(w_star[1]) > 1e-9:\n",
        "    ym = -(w_star[0]/w_star[1])*xm - b_star/(w_star[1]+1e-12)\n",
        "    ax.text(xm, ym, r\"$w^\\top x + b = 0$\", fontsize=10,\n",
        "            bbox=dict(facecolor='white', edgecolor='none', alpha=0.8))\n",
        "else:\n",
        "    ax.text(-b_star/(w_star[0]+1e-9), 0.5*(y_min+y_max), r\"$w^\\top x + b = 0$\", fontsize=10,\n",
        "            bbox=dict(facecolor='white', edgecolor='none', alpha=0.8), rotation=90)\n",
        "\n",
        "ax.legend(loc=\"upper right\"); plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ----------------- CURVA DE ERRORES -----------------\n",
        "errors = [e for (_,_,e) in hist]\n",
        "plt.figure(figsize=(6,3.5))\n",
        "plt.plot(np.arange(1,len(errors)+1), errors, marker=\"o\")\n",
        "plt.xlabel(\"Época\"); plt.ylabel(\"# errores (actualizaciones)\")\n",
        "plt.title(\"Perceptrón: errores por época (no separable)\")\n",
        "plt.grid(True); plt.tight_layout(); plt.show()"
      ],
      "metadata": {
        "id": "yHbvA0d8YkAK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}