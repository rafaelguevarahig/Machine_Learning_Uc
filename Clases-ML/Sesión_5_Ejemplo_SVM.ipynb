{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Ejemplo"
      ],
      "metadata": {
        "id": "bdW8bwiVftmj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "igf__3hCcR8M"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_classification, make_moons\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "np.random.seed(42)\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "\n",
        "# a) Conjunto linealmente separable\n",
        "X_lin, y_lin = make_classification(n_samples=500, n_features=2, n_informative=2,\n",
        "                                   n_redundant=0, n_clusters_per_class=1,\n",
        "                                   class_sep=2.0, random_state=7)\n",
        "X_lin = StandardScaler().fit_transform(X_lin)\n",
        "\n",
        "# b) Conjunto no lineal (moons)\n",
        "X_nl, y_nl = make_moons(n_samples=500, noise=0.2, random_state=7)\n",
        "X_nl = StandardScaler().fit_transform(X_nl)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_decision_boundary(clf, X, y, ax, title=\"\"):\n",
        "    xx, yy = np.meshgrid(np.linspace(X[:,0].min()-1, X[:,0].max()+1, 300),\n",
        "                         np.linspace(X[:,1].min()-1, X[:,1].max()+1, 300))\n",
        "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
        "    ax.contourf(xx, yy, Z, alpha=0.15, levels=np.arange(-0.5, 2, 1), cmap='bwr')\n",
        "    ax.scatter(X[:,0], X[:,1], c=y, cmap='bwr', s=12, edgecolor='k')\n",
        "    ax.set_title(title)\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(10,4))\n",
        "\n",
        "lin1 = LinearSVC(C=1.0, dual=False, max_iter=5000, random_state=0)\n",
        "lin1.fit(X_lin, y_lin)\n",
        "plot_decision_boundary(lin1, X_lin, y_lin, ax[0], \"LinearSVC (lineal)\")\n",
        "\n",
        "lin2 = SVC(kernel='linear', C=1.0, random_state=0)\n",
        "lin2.fit(X_lin, y_lin)\n",
        "plot_decision_boundary(lin2, X_lin, y_lin, ax[1], \"SVC(kernel='linear')\")\n",
        "\n",
        "plt.suptitle(\"SVM lineal: LinearSVC vs SVC(kernel='linear')\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"LinearSVC soporte (no expone SVs):\", \"no disponible\")\n",
        "print(\"SVC(kernel='linear') soporte:\", lin2.support_.shape[0])"
      ],
      "metadata": {
        "id": "gDuxlIAPcu2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kernels = [\n",
        "    (\"linear\", dict(kernel='linear', C=1.0)),\n",
        "    (\"poly (deg=3)\", dict(kernel='poly', C=1.0, degree=3, coef0=1.0, gamma='scale')),\n",
        "    (\"rbf (γ=scale)\", dict(kernel='rbf', C=1.0, gamma='scale')),\n",
        "    (\"sigmoid\", dict(kernel='sigmoid', C=1.0, coef0=1.0, gamma='scale')),\n",
        "]\n",
        "\n",
        "fig, ax = plt.subplots(2, 4, figsize=(14,6))\n",
        "\n",
        "# Arriba: dataset lineal\n",
        "for j, (name, params) in enumerate(kernels):\n",
        "    clf = SVC(**params, random_state=0)\n",
        "    clf.fit(X_lin, y_lin)\n",
        "    plot_decision_boundary(clf, X_lin, y_lin, ax[0,j], f\"{name} (lin)  SV={clf.support_.shape[0]}\")\n",
        "# Abajo: dataset no lineal (moons)\n",
        "for j, (name, params) in enumerate(kernels):\n",
        "    clf = SVC(**params, random_state=0)\n",
        "    clf.fit(X_nl, y_nl)\n",
        "    plot_decision_boundary(clf, X_nl, y_nl, ax[1,j], f\"{name} (moons) SV={clf.support_.shape[0]}\")\n",
        "\n",
        "ax[0,0].set_ylabel(\"Lineal separable\")\n",
        "ax[1,0].set_ylabel(\"No lineal (moons)\")\n",
        "plt.suptitle(\"Comparativa de kernels SVM: lineal / poly / rbf / sigmoide\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "g7J9lgkKdBuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\"C\": [0.1, 1, 10, 100],\n",
        "              \"gamma\": [\"scale\", 0.5, 1.0, 2.0]}\n",
        "clf = GridSearchCV(SVC(kernel='rbf'), param_grid, cv=5, n_jobs=-1)\n",
        "clf.fit(X_nl, y_nl)\n",
        "print(\"Mejores hiperparámetros (RBF, moons):\", clf.best_params_, \"score:\", clf.best_score_)\n",
        "best = clf.best_estimator_\n",
        "\n",
        "# Visualizar mejor modelo\n",
        "fig, ax = plt.subplots(1,1, figsize=(5,4))\n",
        "plot_decision_boundary(best, X_nl, y_nl, ax, f\"Mejor RBF: {clf.best_params_}\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "w6HqlCfedJNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ejercicio"
      ],
      "metadata": {
        "id": "279M92yBfrhx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_breast_cancer, load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "def plot_decision_boundary_2d(clf, X2, y, ax=None, title=\"\", plot_support=True, cmap='bwr'):\n",
        "    \"\"\"\n",
        "    X2 es bidimensional (por ejemplo, tras PCA(n_components=2)).\n",
        "    Dibuja frontera y datos. Si clf tiene .support_, marca los SVs.\n",
        "    \"\"\"\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots(1,1, figsize=(5,4))\n",
        "    x_min, x_max = X2[:, 0].min()-1, X2[:, 0].max()+1\n",
        "    y_min, y_max = X2[:, 1].min()-1, X2[:, 1].max()+1\n",
        "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 400),\n",
        "                         np.linspace(y_min, y_max, 400))\n",
        "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
        "    ax.contourf(xx, yy, Z, alpha=0.15, levels=np.arange(-0.5, Z.max()+1.5, 1), cmap=cmap)\n",
        "    scatter = ax.scatter(X2[:, 0], X2[:, 1], c=y, cmap=cmap, s=15, edgecolor='k')\n",
        "    # Marcar SV si aplica (SVC)\n",
        "    if plot_support and hasattr(clf, \"support_\"):\n",
        "        sv = clf.support_\n",
        "        ax.scatter(X2[sv, 0], X2[sv, 1], s=70, facecolors='none', edgecolors='k', linewidths=1.2, label=\"SV\")\n",
        "        ax.legend(loc=\"best\")\n",
        "    ax.set_title(title)\n",
        "    return ax\n"
      ],
      "metadata": {
        "id": "V5_oyXSLfzk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_bc = load_breast_cancer()\n",
        "X_bc = data_bc.data\n",
        "y_bc = data_bc.target  # 0 = malignant, 1 = benign\n",
        "\n",
        "Xtr_bc, Xte_bc, ytr_bc, yte_bc = train_test_split(X_bc, y_bc, test_size=0.25, stratify=y_bc, random_state=0)\n",
        "\n",
        "# Estandarizamos y proyectamos a 2D para visualización clara\n",
        "scaler_bc = StandardScaler().fit(Xtr_bc)\n",
        "Xtr_std = scaler_bc.transform(Xtr_bc)\n",
        "Xte_std = scaler_bc.transform(Xte_bc)\n",
        "\n",
        "pca_bc = PCA(n_components=2, random_state=0).fit(Xtr_std)\n",
        "Xtr_bc_2d = pca_bc.transform(Xtr_std)\n",
        "Xte_bc_2d = pca_bc.transform(Xte_std)\n",
        "\n",
        "print(\"Breast Cancer -> X shape:\", X_bc.shape, \"Clases:\", dict(zip(data_bc.target_names, np.bincount(y_bc))))\n"
      ],
      "metadata": {
        "id": "NhRMgeVrgb7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "    return 1.0 / (1.0 + np.exp(-z))\n",
        "\n",
        "def logistic_loss_and_grad(w, X, y, lam=1e-2):\n",
        "    \"\"\"\n",
        "    w: (d,) ; X: (n,d) ; y in {0,1}\n",
        "    loss = 1/n sum log(1+exp(-(2y-1)*<w,x>)) + lam/2 ||w||^2\n",
        "    grad = -1/n sum ( (2y-1) x * sig(- (2y-1) <w,x>) ) + lam w\n",
        "    \"\"\"\n",
        "    n = X.shape[0]\n",
        "    ypm = 2*y - 1  # {0,1} -> {-1,+1}\n",
        "    z = ypm * (X @ w)\n",
        "    loss = np.mean(np.log(1 + np.exp(-z))) + 0.5*lam*np.dot(w, w)\n",
        "    grad = -(X.T @ (ypm * (1 - sigmoid(z))))/n + lam*w\n",
        "    return loss, grad\n",
        "\n",
        "# Inicialización y GD\n",
        "w = np.zeros(2)\n",
        "eta = 0.5\n",
        "epochs = 300\n",
        "lam = 1e-2\n",
        "hist = []\n",
        "\n",
        "for t in range(epochs):\n",
        "    loss, g = logistic_loss_and_grad(w, Xtr_bc_2d, ytr_bc, lam=lam)\n",
        "    w = w - eta*g\n",
        "    hist.append(loss)\n",
        "\n",
        "print(f\"Loss final GD: {hist[-1]:.4f}\")\n",
        "\n",
        "# Curva de pérdida\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.plot(hist)\n",
        "plt.xlabel(\"Iteración\")\n",
        "plt.ylabel(\"Pérdida logística\")\n",
        "plt.title(\"GD desde cero (Breast Cancer, PCA-2D)\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "# Evaluación y frontera (aprox lineal en 2D)\n",
        "def predict_gd_linear(w, X):\n",
        "    return (X @ w > 0).astype(int)\n",
        "\n",
        "yhat_tr = predict_gd_linear(w, Xtr_bc_2d)\n",
        "yhat_te = predict_gd_linear(w, Xte_bc_2d)\n",
        "print(\"Acc train GD:\", accuracy_score(ytr_bc, yhat_tr))\n",
        "print(\"Acc test  GD:\", accuracy_score(yte_bc, yhat_te))\n",
        "\n",
        "# Dibujo de frontera: recta w^T x = 0\n",
        "xx, yy = np.meshgrid(np.linspace(Xtr_bc_2d[:,0].min()-1, Xtr_bc_2d[:,0].max()+1, 400),\n",
        "                     np.linspace(Xtr_bc_2d[:,1].min()-1, Xtr_bc_2d[:,1].max()+1, 400))\n",
        "Z = (np.c_[xx.ravel(), yy.ravel()] @ w).reshape(xx.shape)\n",
        "\n",
        "plt.figure(figsize=(5,4))\n",
        "plt.contourf(xx, yy, (Z>0).astype(int), alpha=0.15, levels=1, cmap='bwr')\n",
        "plt.contour(xx, yy, Z, levels=[0], colors='k', linewidths=2)\n",
        "plt.scatter(Xtr_bc_2d[:,0], Xtr_bc_2d[:,1], c=ytr_bc, cmap='bwr', s=15, edgecolor='k')\n",
        "plt.title(\"Frontera GD (regresión logística en PCA-2D)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "D6eikApEgkQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# - Cambia eta (0.1, 0.3, 0.8) y observa estabilidad/velocidad.\n",
        "# - Cambia lam (1e-3, 1e-1) y compara el margen (norma de w) y performance."
      ],
      "metadata": {
        "id": "fPhpGwlB48UR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf_lr = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"pca\", PCA(n_components=2, random_state=0)),\n",
        "    (\"lr\", LogisticRegression(penalty=\"l2\", C=1/1e-2, solver=\"lbfgs\", max_iter=1000, random_state=0))\n",
        "])\n",
        "clf_lr.fit(Xtr_bc, ytr_bc)\n",
        "print(\"Acc train LR:\", accuracy_score(ytr_bc, clf_lr.predict(Xtr_bc)))\n",
        "print(\"Acc test  LR:\", accuracy_score(yte_bc, clf_lr.predict(Xte_bc)))\n",
        "print(confusion_matrix(yte_bc, clf_lr.predict(Xte_bc)))\n",
        "print(classification_report(yte_bc, clf_lr.predict(Xte_bc), target_names=data_bc.target_names))\n"
      ],
      "metadata": {
        "id": "rVUM15dEgm-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_iris = load_iris()\n",
        "X_ir = data_iris.data\n",
        "y_ir = data_iris.target  # 3 clases\n",
        "\n",
        "Xtr_ir, Xte_ir, ytr_ir, yte_ir = train_test_split(X_ir, y_ir, test_size=0.25, stratify=y_ir, random_state=0)\n",
        "\n",
        "scaler_ir = StandardScaler().fit(Xtr_ir)\n",
        "Xtr_ir_std = scaler_ir.transform(Xtr_ir)\n",
        "Xte_ir_std = scaler_ir.transform(Xte_ir)\n",
        "\n",
        "pca_ir = PCA(n_components=2, random_state=0).fit(Xtr_ir_std)\n",
        "Xtr_ir_2d = pca_ir.transform(Xtr_ir_std)\n",
        "Xte_ir_2d = pca_ir.transform(Xte_ir_std)\n",
        "\n",
        "print(\"Iris -> X shape:\", X_ir.shape, \"Clases:\", data_iris.target_names)\n"
      ],
      "metadata": {
        "id": "sBCFoa9PgsDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lin_linsvc = LinearSVC(C=1.0, dual=False, max_iter=10000, random_state=0)\n",
        "lin_svc    = SVC(kernel=\"linear\", C=1.0, random_state=0, decision_function_shape=\"ovr\")\n",
        "\n",
        "lin_linsvc.fit(Xtr_ir_2d, ytr_ir)\n",
        "lin_svc.fit(Xtr_ir_2d, ytr_ir)\n",
        "\n",
        "print(\"[Iris - PCA2D] Acc test LinearSVC:\", accuracy_score(yte_ir, lin_linsvc.predict(Xte_ir_2d)))\n",
        "print(\"[Iris - PCA2D] Acc test SVC(linear):\", accuracy_score(yte_ir, lin_svc.predict(Xte_ir_2d)))\n",
        "print(\"SVC(linear) #SV:\", lin_svc.support_.shape[0])\n",
        "\n",
        "fig, ax = plt.subplots(1,2, figsize=(10,4))\n",
        "plot_decision_boundary_2d(lin_linsvc, Xtr_ir_2d, ytr_ir, ax=ax[0], title=\"LinearSVC (Iris, PCA-2D)\", plot_support=False, cmap='tab10')\n",
        "plot_decision_boundary_2d(lin_svc,    Xtr_ir_2d, ytr_ir, ax=ax[1], title=\"SVC(kernel='linear') (Iris, PCA-2D)\", plot_support=True,  cmap='tab10')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "riz7aiPrgvM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# - Cambia C (0.1, 1, 10) en ambos y observa cambios de frontera y #SV (solo SVC expone SV)."
      ],
      "metadata": {
        "id": "OVercSJk5AkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kernels = [\n",
        "    (\"linear\", dict(kernel=\"linear\", C=1.0)),\n",
        "    (\"poly(d=3)\", dict(kernel=\"poly\", C=1.0, degree=3, gamma=\"scale\", coef0=1.0)),\n",
        "    (\"rbf\", dict(kernel=\"rbf\", C=1.0, gamma=\"scale\")),\n",
        "]\n",
        "\n",
        "fig, ax = plt.subplots(1, 3, figsize=(14,4))\n",
        "for j, (name, params) in enumerate(kernels):\n",
        "    clf = SVC(**params, random_state=0, decision_function_shape=\"ovr\")\n",
        "    clf.fit(Xtr_ir_2d, ytr_ir)\n",
        "    plot_decision_boundary_2d(clf, Xtr_ir_2d, ytr_ir, ax=ax[j], title=f\"{name} (Iris, PCA-2D)\\nSV={clf.support_.shape[0]}\", cmap='tab10')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Evaluación en el test (en PCA-2D)\n",
        "for name, params in kernels:\n",
        "    clf = SVC(**params, random_state=0, decision_function_shape=\"ovr\").fit(Xtr_ir_2d, ytr_ir)\n",
        "    print(f\"[{name}] Acc test (Iris, PCA-2D):\", accuracy_score(yte_ir, clf.predict(Xte_ir_2d)))\n"
      ],
      "metadata": {
        "id": "BgzWEmFzgzCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe_rbf = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"clf\", SVC(kernel=\"rbf\", decision_function_shape=\"ovr\", random_state=0))\n",
        "])\n",
        "param_grid = {\"clf__C\": [0.1, 1, 10, 100],\n",
        "              \"clf__gamma\": [\"scale\", 0.1, 0.5, 1.0, 2.0]}\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
        "gs = GridSearchCV(pipe_rbf, param_grid, cv=cv, n_jobs=-1, scoring=\"accuracy\")\n",
        "gs.fit(Xtr_ir, ytr_ir)\n",
        "\n",
        "print(\"Mejores hiperparámetros RBF (Iris full):\", gs.best_params_, \"score CV:\", gs.best_score_)\n",
        "best = gs.best_estimator_\n",
        "print(\"Acc test mejor RBF:\", accuracy_score(yte_ir, best.predict(Xte_ir)))\n",
        "print(confusion_matrix(yte_ir, best.predict(Xte_ir)))\n",
        "print(classification_report(yte_ir, best.predict(Xte_ir), target_names=data_iris.target_names))"
      ],
      "metadata": {
        "id": "Hj-6ZYJgg5kV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# - Cambia la métrica de scoring a 'f1_macro' y discute diferencias.\n",
        "# - Compara #SV del mejor RBF (entrenando fuera del pipeline para inspeccionarlo) vs. lineal."
      ],
      "metadata": {
        "id": "jZ2lrtSGg-Xi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}